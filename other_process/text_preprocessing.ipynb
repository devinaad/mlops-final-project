{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992e4dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS VivoBook\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69502ac5a70a4ad2913208e2be31161c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved FAISS index to 'job_index.faiss' and job_df to 'job_df.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def normalize(vectors):\n",
    "    \"\"\"Normalize vectors using L2 normalization\"\"\"\n",
    "    return vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "def create_and_save_job_embeddings(csv_path, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                   faiss_path=\"job_index.faiss\", df_path=\"job_df.pkl\"):\n",
    "    \"\"\"\n",
    "    Create and save job embeddings from a CSV file\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to CSV with 'Job Title' and 'Job Description'\n",
    "        model_name (str): SentenceTransformer model\n",
    "        faiss_path (str): Output path for FAISS index\n",
    "        df_path (str): Output path to save job_df (pickled DataFrame)\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Load CSV\n",
    "    job_df = pd.read_csv(csv_path)\n",
    "    job_df['job_text'] = job_df['Job Title'] + \" \" + job_df['Job Description']\n",
    "\n",
    "    # Encode & Normalize\n",
    "    job_texts = job_df['job_text'].tolist()\n",
    "    print(\"ðŸ”„ Creating embeddings...\")\n",
    "    embeddings = model.encode(job_texts, show_progress_bar=True)\n",
    "    embeddings = normalize(embeddings)\n",
    "\n",
    "    # Create FAISS index\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(embeddings.astype(np.float32))\n",
    "\n",
    "    # Save\n",
    "    faiss.write_index(index, faiss_path)\n",
    "    job_df.to_pickle(df_path)\n",
    "    print(f\"âœ… Saved FAISS index to '{faiss_path}' and job_df to '{df_path}'\")\n",
    "\n",
    "# Example usage:\n",
    "create_and_save_job_embeddings(\"job_title_des.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ae45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
